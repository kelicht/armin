{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datasets import Dataset\n",
    "from armin import AlgorithmicRecourseExplainer, ArminExplainer\n",
    "from armin.baselines import ImputationAlgorithmicRecourseExplainer, RobustAlgorithmicRecourseExplainer\n",
    "from armin.missing_helper import MissingGenerator, SingleImputer, MultipleImputer\n",
    "from armin._utils import sign_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "DATASETS = ['f', 'e', 's', 'w']\n",
    "MODELS = ['L', 'M', 'F']\n",
    "MAX_N_MISSING = 3\n",
    "MAX_CHANGE_NUM = 4\n",
    "CONFIDENCE = 0.75\n",
    "CONFIDENCES = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "N_SAMPLING = 100\n",
    "N_SAMPLINGS = [100, 200, 300, 400, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1. Baseline Comparison under MCAR Situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(\n",
    "        N=3, \n",
    "        dataset='f', \n",
    "        model='L',\n",
    "        max_n_missing=1,\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=4,\n",
    "        confidences=[0.5],\n",
    "        n_sampling=100,\n",
    "        time_limit=60,\n",
    "        verbose=True,\n",
    "    ):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    if model=='L':\n",
    "        clf = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    elif model=='M':\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(30,), max_iter=500, activation='relu', alpha=0.0001)\n",
    "    elif model=='F':\n",
    "        clf = RandomForestClassifier(n_estimators=50, max_leaf_nodes=8, class_weight='balanced')\n",
    "\n",
    "    D = Dataset(dataset=dataset)\n",
    "    X_tr, X_ts, y_tr, y_ts = D.get_dataset(split=True, test_size=0.25)\n",
    "    clf = clf.fit(X_tr, y_tr)\n",
    "    X = X_ts[clf.predict(X_ts)==1][:N]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    mg = MissingGenerator(D.feature_types, D.feature_categories)\n",
    "    si_mean = SingleImputer(imputer_type='mean', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "    si_knn = SingleImputer(imputer_type='knn', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "    si_mice = SingleImputer(imputer_type='mice', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "    mi = MultipleImputer(n_sampling=n_sampling, imputer_type='mice', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "\n",
    "    ar = AlgorithmicRecourseExplainer(clf, X_tr, y_tr, **D.params)\n",
    "    iar_mean = ImputationAlgorithmicRecourseExplainer(clf, si_mean, X_tr, y_tr, **D.params)\n",
    "    iar_knn = ImputationAlgorithmicRecourseExplainer(clf, si_knn, X_tr, y_tr, **D.params)\n",
    "    iar_mice = ImputationAlgorithmicRecourseExplainer(clf, si_mice, X_tr, y_tr, **D.params)\n",
    "    rar = RobustAlgorithmicRecourseExplainer(clf, mi, X_tr, y_tr, **D.params)\n",
    "    armin = ArminExplainer(clf, mi, X_tr, y_tr, **D.params)\n",
    "\n",
    "    methods = ['mean', 'knn', 'mice', 'robust', 'armin']\n",
    "    results = {\n",
    "        'n_missing': [],\n",
    "        'method': [],\n",
    "        'confidence': [],\n",
    "        'feasible': [], \n",
    "        'valid': [], \n",
    "        'cost': [], \n",
    "        'relative_cost': [], \n",
    "        'time': [], \n",
    "        'probability_target': [], \n",
    "        'sign_agreement': [], \n",
    "        'y_init': [], \n",
    "    }\n",
    "    keys = results.keys()\n",
    "\n",
    "    def update_result_dict(action, n_missing, method, confidence, a_opt, c_opt):\n",
    "        action['n_missing'] = n_missing \n",
    "        action['method'] = method \n",
    "        action['sign_agreement'] = sign_agreement(action['action'], a_opt)\n",
    "        action['relative_cost'] = action['cost'] / c_opt \n",
    "        action['confidence'] = confidence\n",
    "        for key in keys: results[key].append(action[key])\n",
    "\n",
    "    for n in tqdm(range(N)):\n",
    "        if verbose:\n",
    "            print('# Instance', n+1)\n",
    "\n",
    "        action = ar.extract(X[n], max_change_num=max_change_num, cost_type=cost_type)\n",
    "        if not action['solved']: continue\n",
    "        a_opt = action['action']; c_opt = action['cost']; \n",
    "        update_result_dict(action, 0, 'optimal', 1, a_opt, c_opt)\n",
    "        if verbose:\n",
    "            print('## Optimal action before missing')\n",
    "            print(ar.getActionObject(action))\n",
    "\n",
    "        for n_missing in tqdm(range(1, max_n_missing+1), leave=False):\n",
    "            \n",
    "            x_missing = mg.mask_instance(X[n], n_missing=n_missing)\n",
    "            if verbose:\n",
    "                print('## Action after missing (n_missing = {})'.format(n_missing))\n",
    "\n",
    "            for method, bar in zip(methods, [iar_mean, iar_knn, iar_mice, rar]):\n",
    "                action = bar.extract(x_missing, max_change_num=max_change_num, cost_type=cost_type)\n",
    "                action = bar.updateActionDicts(X[n], action)\n",
    "                update_result_dict(action, n_missing, method, 1, a_opt, c_opt)\n",
    "                if verbose:\n",
    "                    print('### Baseline ({})'.format(method))\n",
    "                    print(bar.getActionObject(action))\n",
    "\n",
    "            for confidence in confidences:\n",
    "                action = armin.extract(x_missing, confidence=confidence, max_change_num=max_change_num, cost_type=cost_type, time_limit=time_limit)\n",
    "                action = armin.updateActionDicts(X[n], action)\n",
    "                update_result_dict(action, n_missing, 'armin', confidence, a_opt, c_opt)\n",
    "                if verbose:\n",
    "                    print('### ARMIN (conf. = {})'.format(confidence))\n",
    "                    print(armin.getActionObject(action))\n",
    "\n",
    "    pd.DataFrame(results).to_csv('./res/{}/{}_{}.csv'.format(model, dataset, cost_type), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODELS:\n",
    "    for dataset in DATASETS:\n",
    "        run_comparison(\n",
    "            N=N, \n",
    "            dataset=dataset, \n",
    "            model=model,\n",
    "            max_n_missing=MAX_N_MISSING,\n",
    "            cost_type='TLPS',\n",
    "            max_change_num=MAX_CHANGE_NUM,\n",
    "            confidences=[CONFIDENCE],\n",
    "            n_sampling=N_SAMPLING,\n",
    "            verbose=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2. Comparison under MAR and MNAR Situations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gmc(\n",
    "        N=3, \n",
    "        situation='MAR',\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=4,\n",
    "        confidences=[0.5],\n",
    "        n_sampling=100,\n",
    "        verbose=True,\n",
    "    ):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    clf = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    D = Dataset(dataset='g')\n",
    "    X_tr, X_ts, y_tr, y_ts = D.get_dataset(split=True, test_size=0.25)\n",
    "    clf = clf.fit(X_tr, y_tr)\n",
    "\n",
    "    if situation=='MAR':\n",
    "        X_old = X_ts[X_ts[:, 1] > np.median(X_tr[:, 1])]\n",
    "    elif situation=='MNAR':\n",
    "        X_old = X_ts[X_ts[:, 4] > np.median(X_tr[:, 4])]\n",
    "    X = X_old[clf.predict(X_old)==1][:N]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    mg = MissingGenerator(D.feature_types, D.feature_categories)\n",
    "    si_mean = SingleImputer(imputer_type='mean', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "    si_knn = SingleImputer(imputer_type='knn', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "    si_mice = SingleImputer(imputer_type='mice', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "    mi = MultipleImputer(n_sampling=n_sampling, imputer_type='mice', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "\n",
    "    ar = AlgorithmicRecourseExplainer(clf, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    iar_mean = ImputationAlgorithmicRecourseExplainer(clf, si_mean, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    iar_knn = ImputationAlgorithmicRecourseExplainer(clf, si_knn, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    iar_mice = ImputationAlgorithmicRecourseExplainer(clf, si_mice, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    rar = RobustAlgorithmicRecourseExplainer(clf, mi, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    armin = ArminExplainer(clf, mi, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "\n",
    "    methods = ['mean', 'knn', 'mice', 'robust', 'armin']\n",
    "    results = {\n",
    "        'n_missing': [],\n",
    "        'method': [],\n",
    "        'confidence': [],\n",
    "        'feasible': [], \n",
    "        'valid': [], \n",
    "        'cost': [], \n",
    "        'relative_cost': [], \n",
    "        'time': [], \n",
    "        'probability_target': [], \n",
    "        'sign_agreement': [], \n",
    "        'y_init': [], \n",
    "    }\n",
    "    keys = results.keys()\n",
    "\n",
    "    def update_result_dict(action, n_missing, method, confidence, a_opt, c_opt):\n",
    "        action['n_missing'] = n_missing \n",
    "        action['method'] = method \n",
    "        action['sign_agreement'] = sign_agreement(action['action'], a_opt)\n",
    "        action['relative_cost'] = action['cost'] / c_opt \n",
    "        action['confidence'] = confidence\n",
    "        for key in keys: results[key].append(action[key])\n",
    "\n",
    "    for n in tqdm(range(N)):\n",
    "        if verbose:\n",
    "            print('# Instance', n+1)\n",
    "\n",
    "        action = ar.extract(X[n], max_change_num=max_change_num, cost_type=cost_type)\n",
    "        if (not action['solved']) or (not action['valid']): continue\n",
    "        a_opt = action['action']; c_opt = action['cost']; \n",
    "        update_result_dict(action, 0, 'optimal', 1, a_opt, c_opt)\n",
    "        if verbose:\n",
    "            print('## Optimal action before missing')\n",
    "            print(ar.getActionObject(action))\n",
    "            \n",
    "        x_missing = mg.mask_instance(X[n], n_missing=1, m_=[4])\n",
    "        if verbose:\n",
    "            print('## Action after missing')\n",
    "\n",
    "        for method, bar in zip(methods, [iar_mean, iar_knn, iar_mice, rar]):\n",
    "            action = bar.extract(x_missing, max_change_num=max_change_num, cost_type=cost_type)\n",
    "            action = bar.updateActionDicts(X[n], action)\n",
    "            update_result_dict(action, 1, method, 1, a_opt, c_opt)\n",
    "            if verbose:\n",
    "                print('### Baseline ({})'.format(method))\n",
    "                print(bar.getActionObject(action))\n",
    "\n",
    "        for confidence in confidences:\n",
    "            action = armin.extract(x_missing, confidence=confidence, max_change_num=max_change_num, cost_type=cost_type)\n",
    "            action = armin.updateActionDicts(X[n], action)\n",
    "            update_result_dict(action, 1, 'armin', confidence, a_opt, c_opt)\n",
    "            if verbose:\n",
    "                print('### ARMIN (conf. = {})'.format(confidence))\n",
    "                print(armin.getActionObject(action))\n",
    "\n",
    "    pd.DataFrame(results).to_csv('./res/L/g_{}_{}.csv'.format(situation, cost_type), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for situation in ['MAR', 'MNAR']:\n",
    "    run_gmc(\n",
    "        N=N, \n",
    "        situation=situation,\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=MAX_CHANGE_NUM,\n",
    "        confidences=CONFIDENCES,\n",
    "        n_sampling=N_SAMPLING,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3. Confidence Path Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_path(\n",
    "        N=1,\n",
    "        situation='MAR',\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=4,\n",
    "        n_sampling=100,\n",
    "        verbose=True,\n",
    "    ):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    clf = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    D = Dataset(dataset='g')\n",
    "    X_tr, X_ts, y_tr, y_ts = D.get_dataset(split=True, test_size=0.25)\n",
    "    clf = clf.fit(X_tr, y_tr)\n",
    "\n",
    "    if situation=='MAR':\n",
    "        X_old = X_ts[X_ts[:, 1] > np.median(X_tr[:, 1])]\n",
    "    elif situation=='MNAR':\n",
    "        X_old = X_ts[X_ts[:, 4] > np.median(X_tr[:, 4])]\n",
    "    X = X_old[clf.predict(X_old)==1]\n",
    "\n",
    "    y_prob_inits = clf.predict_proba(X)[:, 0]\n",
    "    y_prob_sorted = np.argsort(y_prob_inits)\n",
    "    X = X[y_prob_sorted]\n",
    "    y_prob_inits = y_prob_inits[y_prob_sorted]\n",
    "    Ns = np.sort(np.random.choice(np.arange(X.shape[0]), N, replace=False))\n",
    "\n",
    "    mg = MissingGenerator(D.feature_types, D.feature_categories)\n",
    "    mi = MultipleImputer(n_sampling=n_sampling, imputer_type='mice', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "\n",
    "    ar = AlgorithmicRecourseExplainer(clf, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    armin = ArminExplainer(clf, mi, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "\n",
    "    results = {\n",
    "        'n': [],\n",
    "        'n_missing': [],\n",
    "        'method': [],\n",
    "        'confidence': [],\n",
    "        'feasible': [], \n",
    "        'valid': [], \n",
    "        'cost': [], \n",
    "        'relative_cost': [], \n",
    "        'time': [], \n",
    "        'probability_target': [], \n",
    "        'sign_agreement': [], \n",
    "        'y_prob_init': [], \n",
    "    }\n",
    "    keys = results.keys()\n",
    "\n",
    "    def update_result_dict(action, n, n_missing, method, confidence, a_opt, c_opt, y_prob_init):\n",
    "        action['n'] = n \n",
    "        action['n_missing'] = n_missing \n",
    "        action['method'] = method \n",
    "        action['sign_agreement'] = sign_agreement(action['action'], a_opt)\n",
    "        action['relative_cost'] = action['cost'] / c_opt \n",
    "        action['confidence'] = confidence\n",
    "        action['y_prob_init'] = y_prob_init\n",
    "        for key in keys: results[key].append(action[key])\n",
    "\n",
    "    for n in tqdm(Ns):\n",
    "        if verbose:\n",
    "            print('# Instance', n+1)\n",
    "            \n",
    "        action = ar.extract(X[n], max_change_num=max_change_num, cost_type=cost_type)\n",
    "        if (not action['solved']) or (not action['valid']): continue\n",
    "        a_opt = action['action']; c_opt = action['cost']; \n",
    "        update_result_dict(action, n, 0, 'optimal', 1, a_opt, c_opt, y_prob_inits[n])\n",
    "        if verbose:\n",
    "            print('## Optimal action before missing')\n",
    "            print(ar.getActionObject(action))\n",
    "            \n",
    "        x_missing = mg.mask_instance(X[n], n_missing=1, m_=[4])\n",
    "        if verbose:\n",
    "            print('## Action after missing')\n",
    "\n",
    "        path = armin.confidence_path(x_missing, max_change_num=max_change_num, cost_type=cost_type)\n",
    "        for (confidence, action) in path:\n",
    "            action = armin.updateActionDicts(X[n], action)\n",
    "            update_result_dict(action, n, 1, 'armin', confidence, a_opt, c_opt, y_prob_inits[n])\n",
    "            if verbose:\n",
    "                print('### ARMIN (conf. = {})'.format(confidence))\n",
    "                print(armin.getActionObject(action))\n",
    "\n",
    "    pd.DataFrame(results).to_csv('./res/L/path_g_{}_{}.csv'.format(situation, cost_type), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for situation in ['MAR', 'MNAR']:\n",
    "    run_path(\n",
    "        N=N, \n",
    "        situation=situation,\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=MAX_CHANGE_NUM,\n",
    "        n_sampling=N_SAMPLING,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4. Sensitivity Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sensitivity(\n",
    "        N=3, \n",
    "        dataset='f', \n",
    "        n_missing=1,\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=4,\n",
    "        confidences=[0.5],\n",
    "        n_samplings=[100],\n",
    "        verbose=True,\n",
    "    ):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    clf = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    D = Dataset(dataset=dataset)\n",
    "    X_tr, X_ts, y_tr, y_ts = D.get_dataset(split=True, test_size=0.25)\n",
    "    clf = clf.fit(X_tr, y_tr)\n",
    "    X = X_ts[clf.predict(X_ts)==1][:N]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    results = {\n",
    "        'n_missing': [],\n",
    "        'method': [],\n",
    "        'confidence': [],\n",
    "        'n_sampling': [],\n",
    "        'feasible': [], \n",
    "        'valid': [], \n",
    "        'cost': [], \n",
    "        'relative_cost': [], \n",
    "        'time': [], \n",
    "        'probability_target': [], \n",
    "        'sign_agreement': [], \n",
    "        'y_init': [], \n",
    "    }\n",
    "    keys = results.keys()\n",
    "\n",
    "    mg = MissingGenerator(D.feature_types, D.feature_categories)\n",
    "    mi = MultipleImputer(imputer_type='mice', feature_types=D.feature_types, feature_categories=D.feature_categories).fit(X_tr)\n",
    "\n",
    "    ar = AlgorithmicRecourseExplainer(clf, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "    armin = ArminExplainer(clf, mi, X_tr, y_tr, **D.params, quantile=(0.01, 0.99))\n",
    "\n",
    "    def update_result_dict(action, n_missing, method, confidence, n_sampling, a_opt, c_opt):\n",
    "        action['n_missing'] = n_missing \n",
    "        action['method'] = method \n",
    "        action['sign_agreement'] = sign_agreement(action['action'], a_opt)\n",
    "        action['relative_cost'] = action['cost'] / c_opt \n",
    "        action['confidence'] = confidence\n",
    "        action['n_sampling'] = n_sampling\n",
    "        for key in keys: results[key].append(action[key])\n",
    "\n",
    "    for n in tqdm(range(N)):\n",
    "        if verbose:\n",
    "            print('# Instance', n+1)\n",
    "\n",
    "        action = ar.extract(X[n], max_change_num=max_change_num, cost_type=cost_type)\n",
    "        if not action['solved']: continue\n",
    "        a_opt = action['action']; c_opt = action['cost']; \n",
    "        update_result_dict(action, 0, 'optimal', 1, 0, a_opt, c_opt)\n",
    "        if verbose:\n",
    "            print('## Optimal action before missing')\n",
    "            print(ar.getActionObject(action))\n",
    "\n",
    "        x_missing = mg.mask_instance(X[n], n_missing=n_missing)\n",
    "        if verbose:\n",
    "            print('## Action after missing (n_missing = {})'.format(n_missing))\n",
    "\n",
    "        for n_sampling in n_samplings:\n",
    "            armin.imputer_.n_sampling = n_sampling\n",
    "            for confidence in confidences:\n",
    "                action = armin.extract(x_missing, confidence=confidence, max_change_num=max_change_num, cost_type=cost_type)\n",
    "                action = armin.updateActionDicts(X[n], action)\n",
    "                update_result_dict(action, n_missing, 'armin', confidence, n_sampling, a_opt, c_opt)\n",
    "                if verbose:\n",
    "                    print('### ARMIN (conf. = {} | n_sampling = {})'.format(confidence, n_sampling))\n",
    "                    print(armin.getActionObject(action))\n",
    "\n",
    "    pd.DataFrame(results).to_csv('./res/L/sens_{}_{}_{}.csv'.format('confidence' if len(n_samplings) == 1 else ('sampling' if len(confidences) == 1 else 'both'), dataset, cost_type), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    run_sensitivity(\n",
    "        N=N, \n",
    "        dataset=dataset, \n",
    "        n_missing=2,\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=MAX_CHANGE_NUM,\n",
    "        confidences=CONFIDENCES,\n",
    "        n_samplings=[N_SAMPLING],\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    run_sensitivity(\n",
    "        N=N, \n",
    "        dataset=dataset, \n",
    "        n_missing=2,\n",
    "        cost_type='TLPS',\n",
    "        max_change_num=MAX_CHANGE_NUM,\n",
    "        confidences=[CONFIDENCE],\n",
    "        n_samplings=N_SAMPLINGS,\n",
    "        verbose=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
